<!DOCTYPE html>
<html>
    <head>
        <title>Kashyap Holla Blog</title>
    </head>
    <body>
        <h1>Titanic - Machine Learning from Disaster</h1>
        <p>In this blog post, by using machine learning, we can approach this question in a systematic and data-driven manner. We will try predicting survival on the Titanic using a logistic regression model.</p>
        <h2>1. Data Loading and Exploration</h2>
        <p>The Titanic dataset is available on Kaggle. It's divided into two parts: train.csv and test.csv. The training dataset includes details about passengers and whether they survived or not. The test dataset contains similar information but without the 'Survived' column - this is what we'll predict.

            A quick look at the data using train.info() and train.head() reveals columns like PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, and Embarked.</p>
        <h2>2. Data Cleaning</h2>
        <p>Machine learning models require clean data. For the Titanic dataset, we:
            <ul>
                <li>Fill Missing Ages: We fill the missing ages with the average age.</li>
                <li>Drop Unnecessary Columns: The Cabin column has too many missing values, so we drop it. We also drop other non-numeric columns like Name, Ticket, and Embarked.</li>
                <li>Convert Categorical Columns: We convert categorical columns like Sex and Embarked into a numeric format using one-hot encoding.</li>
            </ul>
        </p>
        <h2>3. Model Building</h2>
        <p>With clean data in hand, we split it into training and testing sets and train a logistic regression model. This model will learn from the training data and then predict if a passenger survived or not based on their features.
            <br><br>
            from sklearn.linear_model import LogisticRegression 
            <br>
            logmodel = LogisticRegression()
            <br>
            logmodel.fit(X_train, y_train)</p>
        <h2>4. Model Evaluation</h2>
        <p>After training the model, we evaluate its performance on the test data. We use metrics like: <br>
            <ul>
                <li>Confusion Matrix: This shows the number of true positive, true negative, false positive, and false negative predictions.</li>
                <li>Classification Report: This provides a more detailed performance analysis, including precision, recall, and f1-score.</li>
            </ul>
            </p>
        <h2>5. Code</h2>
        <a href="Data/titanic.ipynb" download="Data/titanic.ipynb" target="_blank">Code</a>
        <img src="Submission1.jpg" alt="Submission">
        <h2>6. Contribution</h2>
        <p>To improve the performance of this model, I have done more data preprocessing by cleaning and processing data by removing the errors, inconsistencies, and outliers which was negatively impacting the result of my analyses and predictions. By doing this, I was able to improve the accuracy of the model. Below is the new submission after doing extra data preprocessing.</p>
        <img src="Submission2.jpg" alt="Submission">
    </body>
</html>